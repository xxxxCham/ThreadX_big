"""
ThreadX Backtest Engine - Phase 10 (Production)
==============================================

Orchestrateur de backtesting production-ready int√©grant toutes les briques ThreadX.

Features:
- Device-agnostic computing via utils.xp (NumPy/CuPy)
- Multi-GPU distribution via utils.gpu.multi_gpu
- Device detection via utils.gpu.device_manager
- Performance measurement via utils.timing
- Bollinger Bands + ATR strategy avec bank.ensure
- RunResult compatible avec performance.summarize
- D√©terminisme (seed=42), logs structur√©s

Pipeline:
    bank.ensure(indicateurs) ‚Üí engine.run(df, indicators, params) ‚Üí RunResult
    ‚Üí performance.summarize(result.returns, result.trades) ‚Üí metrics/plots

Architecture:
- BacktestEngine : orchestrateur principal
- RunResult : structure de donn√©es standardis√©e
- Multi-device : balance 75%/25% par d√©faut entre GPUs
- Strategy : Bollinger mean reversion + ATR filter

Author: ThreadX Framework
Version: Phase 10 - Production Engine
"""

import logging
import time
from dataclasses import dataclass, field

# ThreadX Common Imports (DRY refactoring)
from threadx.utils.common_imports import (
    pd,
    np,
    Dict,
    Any,
    Optional,
    Tuple,
    List,
    Union,
    create_logger,
)

# Validation backtest anti-overfitting
try:
    from threadx.backtest.validation import (
        BacktestValidator,
        ValidationConfig,
        check_temporal_integrity,
    )

    VALIDATION_AVAILABLE = True
except ImportError:
    VALIDATION_AVAILABLE = False
    BacktestValidator = None
    ValidationConfig = None
    check_temporal_integrity = None

# Threading/Timing utilities avec fallback gracieux
try:
    from threadx.utils.timing import measure_throughput, track_memory

    TIMING_AVAILABLE = True
except ImportError:
    TIMING_AVAILABLE = False

    # Fallback decorators si timing non disponible
    def measure_throughput(name=None, *, unit="task"):
        def decorator(func):
            return func

        return decorator

    def track_memory(name=None):
        def decorator(func):
            return func

        return decorator


# Device-agnostic computing avec fallback NumPy
try:
    from threadx.utils import xp as xp_module

    XP_AVAILABLE = True

    # Couche xp unifi√©e
    def get_xp_module():
        return xp_module.get_xp()

except ImportError:
    XP_AVAILABLE = False
    xp_module = None

    # Fallback NumPy pur
    def get_xp_module():
        return np


# GPU management avec fallback gracieux
try:
    from threadx.utils.gpu.device_manager import (
        list_devices,
        get_device_by_name,
        is_available as gpu_available,
    )
    from threadx.utils.gpu.multi_gpu import MultiGPUManager, get_default_manager

    GPU_UTILS_AVAILABLE = True
except ImportError:
    GPU_UTILS_AVAILABLE = False
    list_devices = lambda: []
    get_device_by_name = lambda x: None
    gpu_available = lambda: False
    MultiGPUManager = None
    get_default_manager = lambda: None

logger = create_logger(__name__)


@dataclass
class RunResult:
    """
    R√©sultat d'ex√©cution de backtest ThreadX.

    Structure de donn√©es standard pour l'√©change entre:
    - BacktestEngine.run() ‚Üí RunResult
    - RunResult ‚Üí PerformanceCalculator.summarize()
    - RunResult ‚Üí UI charts/tables

    Attributes:
        equity: S√©rie d'√©quit√© avec index datetime UTC, dtype float64
        returns: S√©rie des returns avec m√™me index que equity
        trades: DataFrame des trades avec colonnes minimales requises
        meta: M√©tadonn√©es d'ex√©cution (dur√©es, devices, cache, etc.)

    Notes:
        Validation stricte des donn√©es pour garantir la compatibilit√©
        avec performance.summarize() et les modules d'analyse.
    """

    equity: pd.Series
    returns: pd.Series
    trades: pd.DataFrame
    meta: Dict[str, Any] = field(default_factory=dict)

    def __post_init__(self):
        """Validation stricte des donn√©es retourn√©es."""
        # Validation equity
        if not isinstance(self.equity, pd.Series):
            raise TypeError("equity doit √™tre une pd.Series")
        if not pd.api.types.is_datetime64_any_dtype(self.equity.index):
            raise TypeError("equity.index doit √™tre datetime64")
        if self.equity.dtype != np.float64:
            logger.warning(f"equity dtype {self.equity.dtype} != float64, conversion")
            self.equity = self.equity.astype(np.float64)

        # Validation returns
        if not isinstance(self.returns, pd.Series):
            raise TypeError("returns doit √™tre une pd.Series")
        if not self.equity.index.equals(self.returns.index):
            raise ValueError("equity et returns doivent avoir le m√™me index")

        # Validation trades - colonnes requises pour performance.summarize
        required_cols = [
            "entry_ts",
            "exit_ts",
            "pnl",
            "size",
            "price_entry",
            "price_exit",
        ]
        if not isinstance(self.trades, pd.DataFrame):
            raise TypeError("trades doit √™tre un pd.DataFrame")
        missing_cols = [col for col in required_cols if col not in self.trades.columns]
        if missing_cols:
            raise ValueError(f"trades manque colonnes requises: {missing_cols}")


class BacktestEngine:
    """
    Moteur de backtesting unifi√© ThreadX.

    Orchestrateur production-ready qui int√®gre toutes les briques existantes :
    - Device management via utils.gpu.device_manager
    - Multi-GPU distribution via utils.gpu.multi_gpu
    - Device-agnostic computing via utils.xp
    - Performance measurement via utils.timing
    - Strategy implementation with existing IndicatorBank

    Pipeline standard:
    1. bank.ensure(...) ‚Üí indicators
    2. engine.run(df_1m, indicators, params) ‚Üí RunResult
    3. performance.summarize(result.returns, result.trades) ‚Üí metrics
    4. ui.display(result, metrics)

    Features:
    - Multi-GPU: balance 75%/25% par d√©faut (configurable)
    - D√©terminisme: seed=42 pour reproductibilit√©
    - Device fallback: GPU ‚Üí CPU transparent
    - Logs structur√©s: INFO/DEBUG/WARNING/ERROR
    - API RunResult: compatible performance.summarize

    Examples:
        >>> # Usage standard avec IndicatorBank
        >>> from threadx.indicators.bank import IndicatorBank
        >>> from threadx.backtest.engine import BacktestEngine
        >>> from threadx.backtest.performance import PerformanceCalculator
        >>>
        >>> # 1. Calculer indicateurs
        >>> bank = IndicatorBank()
        >>> indicators = {
        ...     "bollinger": bank.ensure("bollinger", {"period": 20, "std": 2.0},
        ...                             df_1m, symbol="BTCUSDC", timeframe="1m"),
        ...     "atr": bank.ensure("atr", {"period": 14}, df_1m,
        ...                       symbol="BTCUSDC", timeframe="1m")
        ... }
        >>>
        >>> # 2. Ex√©cuter backtest
        >>> engine = BacktestEngine()
        >>> result = engine.run(df_1m, indicators,
        ...                     params={"entry_z": 2.0, "k_sl": 1.5, "leverage": 3},
        ...                     symbol="BTCUSDC", timeframe="1m")
        >>>
        >>> # 3. Calculer m√©triques
        >>> perf = PerformanceCalculator()
        >>> metrics = perf.summarize(result.returns, result.trades)
        >>>
        >>> print(f"Sharpe: {metrics['sharpe_ratio']:.3f}")
        >>> print(f"Max DD: {metrics['max_drawdown']:.2%}")
    """

    def __init__(
        self, gpu_balance: Optional[Dict[str, float]] = None, use_multi_gpu: bool = True
    ):
        """
        Initialise le moteur de backtesting.

        Args:
            gpu_balance: Balance multi-GPU personnalis√©e {"5090": 0.75, "2060": 0.25}
                        Si None, utilise balance par d√©faut du MultiGPUManager
            use_multi_gpu: Active la distribution multi-GPU si plusieurs devices
        """
        self.logger = create_logger(__name__)

        # Device detection et setup
        self.gpu_available = gpu_available() if GPU_UTILS_AVAILABLE else False
        self.devices = list_devices() if GPU_UTILS_AVAILABLE else []

        # Multi-GPU setup
        self.use_multi_gpu = use_multi_gpu and len(self.devices) > 1
        self.multi_gpu_manager = None

        if self.use_multi_gpu and GPU_UTILS_AVAILABLE:
            try:
                self.multi_gpu_manager = get_default_manager()
                if gpu_balance and self.multi_gpu_manager:
                    self.multi_gpu_manager.set_balance(gpu_balance)
                self.logger.info(f"üîÄ Multi-GPU activ√©: {len(self.devices)} devices")
            except Exception as e:
                self.logger.warning(
                    f"‚ö†Ô∏è Multi-GPU setup failed: {e}, fallback single device"
                )
                self.use_multi_gpu = False

        # Device-agnostic computing setup
        self.xp_backend = "cpu"
        if XP_AVAILABLE and self.gpu_available:
            try:
                # Configure xp backend pour GPU si disponible
                self.xp_backend = "gpu"
                self.logger.debug("üéØ XP backend configur√©: GPU")
            except Exception as e:
                self.logger.warning(f"‚ö†Ô∏è XP GPU config failed: {e}, fallback CPU")
                self.xp_backend = "cpu"

        # √âtat d'ex√©cution
        self.last_run_meta = {}

        # Validation setup
        self.validator = None
        self.validation_config = None
        if VALIDATION_AVAILABLE:
            # Configuration par d√©faut: walk-forward avec purge/embargo
            self.validation_config = ValidationConfig(
                method="walk_forward",
                walk_forward_windows=5,
                purge_days=1,
                embargo_days=1,
                min_train_samples=200,
                min_test_samples=50,
            )
            self.validator = BacktestValidator(self.validation_config)
            self.logger.info("‚úÖ Validation anti-overfitting activ√©e")

        self.logger.info("üöÄ BacktestEngine initialis√©")
        self.logger.info(f"   GPU: {'‚úÖ' if self.gpu_available else '‚ùå'}")
        self.logger.info(f"   Multi-GPU: {'‚úÖ' if self.use_multi_gpu else '‚ùå'}")
        self.logger.info(f"   XP Backend: {self.xp_backend}")
        self.logger.info(f"   Validation: {'‚úÖ' if self.validator else '‚ùå'}")

    def run(
        self,
        df_1m: pd.DataFrame,
        indicators: Dict[str, Any],
        *,
        params: Dict[str, Any],
        symbol: str,
        timeframe: str,
        seed: int = 42,
        use_gpu: Optional[bool] = None,
    ) -> RunResult:
        """
        Ex√©cute un backtest complet avec strat√©gie Bollinger Bands + ATR.

        Pipeline d'ex√©cution:
        1. Validation donn√©es/param√®tres stricte
        2. Setup backend compute (CPU/GPU/Multi-GPU)
        3. G√©n√©ration signaux via strat√©gie configurable
        4. Simulation trades avec gestion positions r√©aliste
        5. Calcul equity curve et returns
        6. Construction RunResult avec m√©tadonn√©es compl√®tes

        Args:
            df_1m: DataFrame OHLCV 1-minute, index datetime UTC
                   Colonnes requises: open, high, low, close, volume
            indicators: Dict des indicateurs calcul√©s via bank.ensure()
                       Ex: {"bollinger": (upper, middle, lower), "atr": np.array(...)}
            params: Param√®tres de strat√©gie
                   Cl√©s requises: entry_z, k_sl, leverage
                   Optionnelles: risk_pct, trail_k, fees_bps
            symbol: Symbole trad√© (ex: "BTCUSDC")
            timeframe: Timeframe de r√©f√©rence (ex: "1m", "1h")
            seed: Seed pour d√©terminisme (default: 42)
            use_gpu: Force GPU usage (None=auto selon d√©tection)

        Returns:
            RunResult: Structure avec equity, returns, trades, meta

        Raises:
            ValueError: Si donn√©es/param√®tres invalides
            RuntimeError: Si erreur compute non r√©cup√©rable

        Notes:
            Multi-GPU: Si plusieurs devices disponibles, distribue automatiquement
            le workload selon balance configur√©e (75%/25% par d√©faut).

            D√©terminisme: seed=42 appliqu√© √† tous composants pseudo-al√©atoires.

            Performance: @measure_throughput et @track_memory actifs si utils.timing
            disponible, sinon fallback gracieux sans impact.
        """
        start_time = time.time()
        self.logger.info(f"üéØ D√©marrage backtest: {symbol} {timeframe}")
        self.logger.debug(f"   Params: {params}")
        self.logger.debug(f"   Data shape: {df_1m.shape}")
        self.logger.debug(f"   P√©riode: {df_1m.index[0]} ‚Üí {df_1m.index[-1]}")
        self.logger.debug(f"   Indicators: {list(indicators.keys())}")

        # Seed pour d√©terminisme complet
        np.random.seed(seed)

        try:
            # 1. Setup backend et validation
            device_info = self._setup_compute_backend(use_gpu)
            self._validate_inputs(df_1m, indicators, params)

            # 2. G√©n√©ration signaux de trading
            signals = self._generate_trading_signals(df_1m, indicators, params)

            # 3. Simulation trades et gestion positions
            trades_df = self._simulate_trades(df_1m, signals, params)

            # 4. Calcul equity curve et returns
            equity, returns = self._calculate_equity_returns(df_1m, trades_df, params)

            # 5. M√©tadonn√©es d'ex√©cution compl√®tes
            duration = time.time() - start_time
            meta = self._build_metadata(
                device_info, duration, df_1m, trades_df, params, seed
            )

            # 6. Construction RunResult avec validation
            result = RunResult(
                equity=equity, returns=returns, trades=trades_df, meta=meta
            )

            self.last_run_meta = meta
            self.logger.info(f"‚úÖ Backtest termin√© en {duration:.2f}s")
            self.logger.info(
                f"   Trades: {len(trades_df)}, Equity finale: ${equity.iloc[-1]:,.2f}"
            )
            self.logger.debug(f"   Throughput: {len(df_1m)/duration:.0f} ticks/sec")

            return result

        except Exception as e:
            self.logger.error(f"‚ùå Erreur backtest {symbol}: {e}")
            raise

    def _setup_compute_backend(self, use_gpu: Optional[bool]) -> Dict[str, Any]:
        """
        Configure le backend de calcul avec fallback gracieux.

        Args:
            use_gpu: Force GPU usage (None=auto)

        Returns:
            Dict avec info device pour m√©tadonn√©es
        """
        # D√©termination GPU usage
        if use_gpu is None:
            use_gpu = self.gpu_available
        elif use_gpu and not self.gpu_available:
            self.logger.warning("‚ö†Ô∏è GPU requis mais non disponible, fallback CPU")
            use_gpu = False

        # Device info pour m√©tadonn√©es
        if use_gpu and self.use_multi_gpu:
            # Multi-GPU
            device_names = [d.name for d in self.devices if d.name != "cpu"]
            balance = (
                getattr(self.multi_gpu_manager, "device_balance", {})
                if self.multi_gpu_manager
                else {}
            )
            device_info = {
                "mode": "multi_gpu",
                "devices": device_names,
                "balance": balance,
                "backend": "cupy/multi",
            }
            self.logger.debug(f"üîÄ Multi-GPU mode: {device_names}")

        elif use_gpu:
            # Single GPU
            gpu_device = next((d for d in self.devices if d.name != "cpu"), None)
            device_info = {
                "mode": "single_gpu",
                "devices": [gpu_device.name] if gpu_device else ["gpu"],
                "balance": {},
                "backend": "cupy",
            }
            self.logger.debug(
                f"üéØ Single GPU mode: {gpu_device.name if gpu_device else 'default'}"
            )

        else:
            # CPU fallback
            device_info = {
                "mode": "cpu",
                "devices": ["cpu"],
                "balance": {},
                "backend": "numpy",
            }
            self.logger.debug("üñ•Ô∏è CPU mode")

        return device_info

    def _validate_inputs(
        self, df_1m: pd.DataFrame, indicators: Dict[str, Any], params: Dict[str, Any]
    ):
        """Validation stricte des donn√©es d'entr√©e."""
        # Validation DataFrame OHLCV
        if df_1m.empty:
            raise ValueError("df_1m ne peut pas √™tre vide")

        required_cols = ["open", "high", "low", "close", "volume"]
        missing_cols = [col for col in required_cols if col not in df_1m.columns]
        if missing_cols:
            raise ValueError(f"df_1m manque colonnes OHLCV: {missing_cols}")

        if not pd.api.types.is_datetime64_any_dtype(df_1m.index):
            raise ValueError("df_1m.index doit √™tre datetime64 UTC")

        # V√©rification donn√©es coh√©rentes (OHLC logic)
        ohlc_errors = (df_1m["high"] < df_1m[["open", "close"]].max(axis=1)).sum()
        if ohlc_errors > 0:
            self.logger.warning(f"‚ö†Ô∏è {ohlc_errors} barres avec high < max(open,close)")

        # Validation indicateurs
        if not indicators:
            self.logger.warning("‚ö†Ô∏è Aucun indicateur fourni, signaux basiques")

        # Validation param√®tres strat√©gie
        required_params = ["entry_z", "k_sl", "leverage"]
        missing_params = [p for p in required_params if p not in params]
        if missing_params:
            raise ValueError(f"params manque cl√©s requises: {missing_params}")

        # Validation ranges param√®tres
        if params["leverage"] <= 0 or params["leverage"] > 20:
            raise ValueError("leverage doit √™tre dans [0.1, 20]")
        if params["k_sl"] <= 0 or params["k_sl"] > 10:
            raise ValueError("k_sl doit √™tre dans (0, 10]")

        self.logger.debug("‚úÖ Validation inputs r√©ussie")

    @measure_throughput("signal_generation")
    def _generate_trading_signals(
        self, df_1m: pd.DataFrame, indicators: Dict[str, Any], params: Dict[str, Any]
    ) -> pd.Series:
        """
        G√©n√®re signaux de trading via strat√©gie Bollinger Bands + ATR.

        Strat√©gie impl√©ment√©e:
        - Long: prix touche bande basse ET volatilit√© > seuil
        - Short: prix touche bande haute ET volatilit√© > seuil
        - Exit: signal oppos√© ou stop-loss/take-profit
        - Filter: ATR pour √©viter march√©s trop calmes

        Args:
            df_1m: DataFrame OHLCV
            indicators: Dict avec bollinger et atr de bank.ensure
            params: Param√®tres strat√©gie (entry_z, etc.)

        Returns:
            pd.Series: Signaux {-1: short, 0: hold, 1: long}
        """
        self.logger.debug("üé≤ G√©n√©ration signaux Bollinger + ATR")

        # Signaux par d√©faut (hold/flat)
        signals = pd.Series(0, index=df_1m.index, dtype=np.float64, name="signals")

        try:
            # === Strat√©gie principale: Bollinger Bands ===
            if "bollinger" in indicators and indicators["bollinger"]:
                bb_result = indicators["bollinger"]

                if isinstance(bb_result, tuple) and len(bb_result) >= 3:
                    upper, middle, lower = bb_result[:3]

                    # Conversion en Series pandas si arrays NumPy/CuPy
                    if hasattr(upper, "__array__") and not isinstance(upper, pd.Series):
                        upper = pd.Series(np.asarray(upper), index=df_1m.index)
                    if hasattr(lower, "__array__") and not isinstance(lower, pd.Series):
                        lower = pd.Series(np.asarray(lower), index=df_1m.index)
                    if hasattr(middle, "__array__") and not isinstance(
                        middle, pd.Series
                    ):
                        middle = pd.Series(np.asarray(middle), index=df_1m.index)

                    close_prices = df_1m["close"]

                    # Signaux mean reversion Bollinger
                    # Long: prix <= lower band (oversold)
                    long_condition = close_prices <= lower
                    # Short: prix >= upper band (overbought)
                    short_condition = close_prices >= upper

                    signals[long_condition] = 1.0  # Long signal
                    signals[short_condition] = -1.0  # Short signal

                    signal_count = (signals != 0).sum()
                    self.logger.debug(f"   Bollinger signaux: {signal_count} positions")
                    self.logger.debug(
                        f"   Long: {(signals == 1).sum()}, Short: {(signals == -1).sum()}"
                    )

            # === Filtre ATR: ne trade que si volatilit√© suffisante ===
            if "atr" in indicators and indicators["atr"] is not None:
                atr_values = indicators["atr"]

                # Conversion en Series pandas
                if hasattr(atr_values, "__array__") and len(atr_values) == len(df_1m):
                    atr_series = pd.Series(np.asarray(atr_values), index=df_1m.index)

                    # Filtre: volatilit√© > percentile 30% (√©vite march√©s calmes)
                    atr_threshold = atr_series.quantile(0.3)
                    volatility_filter = atr_series > atr_threshold

                    # Applique filtre: supprime signaux en low volatility
                    signals[~volatility_filter] = 0.0

                    filtered_count = (signals != 0).sum()
                    self.logger.debug(
                        f"   ATR filtre: {filtered_count} signaux restants"
                    )
                    self.logger.debug(f"   Seuil ATR: {atr_threshold:.4f}")

            # === Fallback: signaux al√©atoires si pas d'indicateurs valides ===
            if not any(indicators.values()) or (signals == 0).all():
                self.logger.warning("‚ö†Ô∏è Pas d'indicateurs valides, signaux al√©atoires")
                np.random.seed(42)
                random_signals = np.random.choice(
                    [0, 1, -1],
                    size=len(df_1m),
                    p=[0.85, 0.075, 0.075],  # 85% hold, 7.5% long, 7.5% short
                )
                signals = pd.Series(
                    random_signals, index=df_1m.index, dtype=np.float64, name="signals"
                )

        except Exception as e:
            self.logger.error(f"‚ùå Erreur g√©n√©ration signaux: {e}")

            # Fallback s√©curis√©: signaux al√©atoires d√©terministes
            np.random.seed(42)
            random_signals = np.random.choice(
                [0, 1, -1], size=len(df_1m), p=[0.85, 0.075, 0.075]
            )
            signals = pd.Series(
                random_signals, index=df_1m.index, dtype=np.float64, name="signals"
            )

        # Stats finales
        signal_counts = signals.value_counts().to_dict()
        self.logger.debug(f"   Distribution signaux finale: {signal_counts}")

        return signals

    @track_memory("trade_simulation")
    def _simulate_trades(
        self, df_1m: pd.DataFrame, signals: pd.Series, params: Dict[str, Any]
    ) -> pd.DataFrame:
        """
        Simule l'ex√©cution des trades avec gestion positions r√©aliste.

        Features:
        - Position tracking (flat/long/short)
        - Stop-loss configurable via k_sl
        - Sizing bas√© sur leverage et risk management
        - PnL calculation r√©aliste avec slippage/fees
        - Exit reasons tracking pour analyse

        Args:
            df_1m: DataFrame OHLCV
            signals: Signaux de trading {-1, 0, 1}
            params: Param√®tres (leverage, k_sl, etc.)

        Returns:
            pd.DataFrame: Trades avec colonnes requises pour performance.summarize
        """
        self.logger.debug("üíº Simulation des trades")

        trades = []
        position = 0  # 0=flat, 1=long, -1=short
        entry_price = 0.0
        entry_time = None

        # Param√®tres de trading avec defaults
        leverage = params.get("leverage", 3)
        k_sl = params.get("k_sl", 1.5)  # Stop loss % multiplier
        initial_capital = params.get("initial_capital", 10000.0)
        fees_bps = params.get("fees_bps", 10.0)  # 10 bps = 0.1%
        slip_bps = params.get("slip_bps", 5.0)  # 5 bps slippage

        # Conversion en listes pour it√©ration efficace (√©vite pandas.loc overhead)
        timestamps = df_1m.index.tolist()
        closes = df_1m["close"].tolist()
        signal_values = signals.tolist()

        # Simulation trade par trade
        for i, (timestamp, close_price, signal) in enumerate(
            zip(timestamps, closes, signal_values)
        ):

            # === Entr√©e en position ===
            if position == 0 and signal != 0:
                position = signal
                entry_price = close_price * (1 + slip_bps * 0.0001 * signal)  # Slippage
                entry_time = timestamp

                self.logger.debug(
                    f"   Entr√©e {['FLAT','LONG','SHORT'][int(position + 1)]} @ {entry_price:.2f} le {entry_time}"
                )

            # === Sortie de position ===
            elif position != 0:
                exit_condition = False
                exit_reason = ""

                # 1. Signal oppos√© (reversal)
                if signal != 0 and signal != position:
                    exit_condition = True
                    exit_reason = "signal_reverse"

                # 2. Stop-loss (bas√© sur k_sl%)
                elif position == 1 and close_price <= entry_price * (1 - k_sl * 0.01):
                    exit_condition = True
                    exit_reason = "stop_loss"
                elif position == -1 and close_price >= entry_price * (1 + k_sl * 0.01):
                    exit_condition = True
                    exit_reason = "stop_loss"

                # === Ex√©cution sortie ===
                if exit_condition:
                    exit_price = close_price * (
                        1 - slip_bps * 0.0001 * position
                    )  # Slippage oppos√©

                    # Calcul PnL r√©aliste avec fees
                    if position == 1:  # Long position
                        raw_return = (exit_price - entry_price) / entry_price
                    else:  # Short position
                        raw_return = (entry_price - exit_price) / entry_price

                    # Fees totales (entr√©e + sortie)
                    total_fees_pct = fees_bps * 2 * 0.0001  # 2x pour round-trip
                    net_return = raw_return - total_fees_pct

                    # PnL avec leverage sur capital de base
                    pnl = net_return * leverage * initial_capital

                    # Position size (notional)
                    position_size = (
                        abs(position) * leverage * initial_capital / entry_price
                    )

                    trade_record = {
                        "entry_ts": entry_time,
                        "exit_ts": timestamp,
                        "pnl": pnl,
                        "size": position_size,
                        "price_entry": entry_price,
                        "price_exit": exit_price,
                        "side": "LONG" if position == 1 else "SHORT",
                        "exit_reason": exit_reason,
                        "return_pct": net_return * 100,
                        "leverage_used": leverage,
                        "fees_paid": position_size * total_fees_pct,
                    }

                    trades.append(trade_record)

                    # Log trade d√©taill√©
                    self.logger.debug(
                        f"   Exit {trade_record['side']} @ {exit_price:.2f}, "
                        f"PnL: ${pnl:.2f}, Reason: {exit_reason}"
                    )

                    # Reset position
                    position = 0
                    entry_price = 0.0
                    entry_time = None

                    # Nouvelle position si signal pr√©sent apr√®s sortie
                    if signal != 0:
                        position = signal
                        entry_price = close_price * (1 + slip_bps * 0.0001 * signal)
                        entry_time = timestamp

        # === Trade final si position ouverte ===
        # Ferme position ouverte en fin de donn√©es
        if position != 0:
            final_price = closes[-1] * (1 - slip_bps * 0.0001 * position)
            final_time = timestamps[-1]

            if position == 1:
                raw_return = (final_price - entry_price) / entry_price
            else:
                raw_return = (entry_price - final_price) / entry_price

            total_fees_pct = fees_bps * 2 * 0.0001
            net_return = raw_return - total_fees_pct
            pnl = net_return * leverage * initial_capital
            position_size = abs(position) * leverage * initial_capital / entry_price

            trades.append(
                {
                    "entry_ts": entry_time,
                    "exit_ts": final_time,
                    "pnl": pnl,
                    "size": position_size,
                    "price_entry": entry_price,
                    "price_exit": final_price,
                    "side": "LONG" if position == 1 else "SHORT",
                    "exit_reason": "end_of_data",
                    "return_pct": net_return * 100,
                    "leverage_used": leverage,
                    "fees_paid": position_size * total_fees_pct,
                }
            )

        # Construction DataFrame final
        trades_df = pd.DataFrame(trades)

        # Stats de trading compl√®tes
        if not trades_df.empty:
            total_pnl = trades_df["pnl"].sum()
            total_fees = trades_df["fees_paid"].sum()
            win_rate = (trades_df["pnl"] > 0).mean()
            avg_win = (
                trades_df[trades_df["pnl"] > 0]["pnl"].mean()
                if (trades_df["pnl"] > 0).any()
                else 0
            )
            avg_loss = (
                trades_df[trades_df["pnl"] < 0]["pnl"].mean()
                if (trades_df["pnl"] < 0).any()
                else 0
            )

            self.logger.debug(f"   Trades simul√©s: {len(trades_df)}")
            self.logger.debug(f"   PnL total: ${total_pnl:.2f}")
            self.logger.debug(f"   Fees totales: ${total_fees:.2f}")
            self.logger.debug(f"   Win rate: {win_rate:.2%}")
            self.logger.debug(f"   Avg win/loss: ${avg_win:.2f} / ${avg_loss:.2f}")
        else:
            self.logger.debug("   Aucun trade g√©n√©r√©")

        return trades_df

    def _calculate_equity_returns(
        self, df_1m: pd.DataFrame, trades_df: pd.DataFrame, params: Dict[str, Any]
    ) -> Tuple[pd.Series, pd.Series]:
        """
        Calcule l'equity curve et les returns s√©ries.

        M√©thodologie:
        1. Equity de base = capital initial constant
        2. Applique PnL cumul√© des trades √† leurs dates de sortie
        3. Calculate returns = pct_change() de l'equity
        4. Assure dtype float64 pour compatibilit√© performance.summarize

        Args:
            df_1m: DataFrame OHLCV pour index temporel
            trades_df: DataFrame des trades ex√©cut√©s
            params: Param√®tres avec initial_capital

        Returns:
            Tuple[pd.Series, pd.Series]: (equity, returns)
        """
        self.logger.debug("üìà Calcul equity curve et returns")

        # Capital initial
        initial_capital = params.get("initial_capital", 10000.0)
        equity = pd.Series(
            initial_capital, index=df_1m.index, name="equity", dtype=np.float64
        )

        if not trades_df.empty:
            # Applique les PnL des trades √† leurs dates de sortie
            cumulative_pnl = 0.0

            for _, trade in trades_df.iterrows():
                exit_ts = trade["exit_ts"]
                cumulative_pnl += trade["pnl"]

                # Applique PnL cumul√© √† partir de la date de sortie
                if exit_ts in equity.index:
                    mask = equity.index >= exit_ts
                    equity.loc[mask] = initial_capital + cumulative_pnl

        # Calcul returns (percentage change)
        returns = equity.pct_change().fillna(0.0)
        returns.name = "returns"

        # Validation et casting final pour performance.summarize
        equity = equity.astype(np.float64)
        returns = returns.astype(np.float64)

        # Stats finales pour logs
        total_return_pct = ((equity.iloc[-1] / equity.iloc[0]) - 1) * 100
        max_equity = equity.max()
        min_equity = equity.min()

        self.logger.debug(f"   Equity finale: ${equity.iloc[-1]:,.2f}")
        self.logger.debug(f"   Return total: {total_return_pct:.2f}%")
        self.logger.debug(f"   Equity range: ${min_equity:,.2f} ‚Üí ${max_equity:,.2f}")

        return equity, returns

    def _build_metadata(
        self,
        device_info: Dict[str, Any],
        duration: float,
        df_1m: pd.DataFrame,
        trades_df: pd.DataFrame,
        params: Dict[str, Any],
        seed: int,
    ) -> Dict[str, Any]:
        """
        Construit les m√©tadonn√©es compl√®tes d'ex√©cution.

        Args:
            device_info: Info devices utilis√©s
            duration: Dur√©e d'ex√©cution en secondes
            df_1m: DataFrame des donn√©es
            trades_df: DataFrame des trades
            params: Param√®tres de strat√©gie
            seed: Seed utilis√©

        Returns:
            Dict: M√©tadonn√©es compl√®tes pour RunResult.meta
        """

        # Calculs d√©riv√©s
        data_points = len(df_1m)
        throughput = data_points / duration if duration > 0 else 0

        # Period analysis
        period_days = (df_1m.index[-1] - df_1m.index[0]).days
        trades_per_day = len(trades_df) / period_days if period_days > 0 else 0

        # Performance flags
        performance_flags = []
        if throughput < 1000:
            performance_flags.append("low_throughput")
        if len(trades_df) == 0:
            performance_flags.append("no_trades")
        if duration > 30:
            performance_flags.append("slow_execution")
        if device_info["mode"] == "cpu" and self.gpu_available:
            performance_flags.append("gpu_fallback")

        # Trading stats
        trading_stats = {}
        if not trades_df.empty:
            trading_stats = {
                "total_pnl": float(trades_df["pnl"].sum()),
                "win_rate": float((trades_df["pnl"] > 0).mean()),
                "avg_trade_pnl": float(trades_df["pnl"].mean()),
                "max_trade_pnl": float(trades_df["pnl"].max()),
                "min_trade_pnl": float(trades_df["pnl"].min()),
                "total_fees": float(
                    trades_df["fees_paid"].sum()
                    if "fees_paid" in trades_df.columns
                    else 0
                ),
                "avg_trade_duration_hours": float(
                    (trades_df["exit_ts"] - trades_df["entry_ts"])
                    .dt.total_seconds()
                    .mean()
                    / 3600
                ),
            }

        return {
            # Execution context
            "engine_version": "Phase 10 - Production",
            "seed": seed,
            "run_timestamp": pd.Timestamp.now(tz="UTC").isoformat(),
            # Device information
            **device_info,
            # Performance metrics
            "duration_seconds": round(duration, 3),
            "data_points": data_points,
            "throughput_points_per_sec": round(throughput, 1),
            "performance_flags": performance_flags,
            # Trading results
            "total_trades": len(trades_df),
            "trades_per_day": round(trades_per_day, 2),
            "period_days": period_days,
            "trading_stats": trading_stats,
            # Strategy parameters (pour reproducibilit√©)
            "strategy_params": params.copy(),
            # Data period info
            "data_start": df_1m.index[0].isoformat(),
            "data_end": df_1m.index[-1].isoformat(),
            # System info (placeholders pour extensions futures)
            "cache_hits": 0,
            "cache_misses": 0,
            "memory_peak_mb": 0,
            # Multi-GPU specifics
            "multi_gpu_enabled": self.use_multi_gpu,
            "gpu_balance": device_info.get("balance", {}),
            "device_count": len(device_info.get("devices", [])),
        }

    def run_backtest_with_validation(
        self,
        df_1m: pd.DataFrame,
        indicators: Dict[str, Any],
        *,
        params: Dict[str, Any],
        symbol: str,
        timeframe: str,
        validation_config: Optional[ValidationConfig] = None,
        seed: int = 42,
        use_gpu: Optional[bool] = None,
    ) -> Dict[str, Any]:
        """
        Ex√©cute backtest avec validation anti-overfitting compl√®te.

        Cette m√©thode applique une validation robuste via walk-forward ou train/test split
        pour d√©tecter l'overfitting et garantir des performances r√©alistes out-of-sample.

        Pipeline:
        1. V√©rification int√©grit√© temporelle des donn√©es (look-ahead bias)
        2. Split donn√©es en train/test selon m√©thode configur√©e
        3. Ex√©cution backtest sur chaque split
        4. Calcul ratio overfitting (IS_sharpe / OOS_sharpe)
        5. Recommandations automatiques bas√©es sur ratio

        Args:
            df_1m: DataFrame OHLCV 1-minute avec index datetime UTC
            indicators: Dict indicateurs calcul√©s via bank.ensure()
            params: Param√®tres strat√©gie (entry_z, k_sl, leverage, etc.)
            symbol: Symbole trad√© (ex: "BTCUSDC")
            timeframe: Timeframe de r√©f√©rence (ex: "1m", "1h")
            validation_config: Configuration validation (None = use default from __init__)
            seed: Seed pour d√©terminisme (default: 42)
            use_gpu: Force GPU usage (None = auto)

        Returns:
            Dict avec:
                - in_sample: M√©triques train (mean/std sharpe, return, drawdown, etc.)
                - out_sample: M√©triques test (idem)
                - overfitting_ratio: IS_sharpe / OOS_sharpe
                - recommendation: Texte explicatif bas√© sur ratio
                - method: M√©thode validation utilis√©e
                - n_windows: Nombre fen√™tres (walk-forward uniquement)
                - all_results: Liste r√©sultats individuels par split

        Raises:
            ValueError: Si validation module non disponible
            ValueError: Si donn√©es ont probl√®mes temporels

        Examples:
            >>> # Validation walk-forward (d√©faut)
            >>> results = engine.run_backtest_with_validation(
            ...     df_1m, indicators, params=params, symbol="BTCUSDC", timeframe="1m"
            ... )
            >>> print(f"Overfitting ratio: {results['overfitting_ratio']:.2f}")
            >>> print(results['recommendation'])
            >>>
            >>> # Train/test split simple
            >>> config = ValidationConfig(method="train_test", train_ratio=0.7)
            >>> results = engine.run_backtest_with_validation(
            ...     df_1m, indicators, params=params, symbol="BTCUSDC", timeframe="1m",
            ...     validation_config=config
            ... )

        Notes:
            - Overfitting ratio < 1.2: ‚úÖ Excellent, strat√©gie robuste
            - Overfitting ratio 1.2-1.5: ‚ö†Ô∏è Acceptable, l√©ger overfitting
            - Overfitting ratio 1.5-2.0: üü° Attention, overfitting mod√©r√©
            - Overfitting ratio > 2.0: üî¥ Critique, strat√©gie non viable
        """
        if not VALIDATION_AVAILABLE:
            raise ValueError(
                "Module validation non disponible. "
                "Installer avec: pip install -e . pour activer threadx.backtest.validation"
            )

        self.logger.info(f"üîç D√©marrage backtest avec validation: {symbol} {timeframe}")

        # V√©rifier int√©grit√© temporelle des donn√©es AVANT validation
        try:
            check_temporal_integrity(df_1m)
            self.logger.debug("‚úÖ Int√©grit√© temporelle valid√©e")
        except ValueError as e:
            self.logger.error(f"‚ùå Probl√®me int√©grit√© temporelle: {e}")
            raise

        # Utiliser config fournie ou celle par d√©faut de l'instance
        config = validation_config or self.validation_config
        if config is None:
            config = ValidationConfig()  # Fallback config par d√©faut
            self.logger.warning("‚ö†Ô∏è Aucune config validation, utilisation d√©faut")

        # Cr√©er validator avec config sp√©cifique
        validator = BacktestValidator(config)

        # D√©finir fonction de backtest √† valider
        def backtest_func(
            data: pd.DataFrame, params_dict: Dict[str, Any]
        ) -> Dict[str, float]:
            """
            Wrapper pour ex√©cuter self.run() et extraire m√©triques n√©cessaires.

            Args:
                data: Sous-ensemble de df_1m (train ou test split)
                params_dict: Param√®tres strat√©gie

            Returns:
                Dict avec m√©triques: sharpe_ratio, total_return, max_drawdown, etc.
            """
            try:
                # Re-calculer indicateurs sur split sp√©cifique
                # (important pour √©viter look-ahead bias!)
                split_indicators = {}
                if "bollinger" in indicators:
                    # Pour simplification, on utilise indicateurs pr√©-calcul√©s
                    # TODO: Re-calculer indicateurs par split pour robustesse totale
                    split_indicators["bollinger"] = indicators["bollinger"]
                if "atr" in indicators:
                    split_indicators["atr"] = indicators["atr"]

                # Ex√©cuter backtest sur ce split
                result = self.run(
                    df_1m=data,
                    indicators=split_indicators,
                    params=params_dict,
                    symbol=symbol,
                    timeframe=timeframe,
                    seed=seed,
                    use_gpu=use_gpu,
                )

                # Calculer m√©triques depuis RunResult
                returns = result.returns
                trades = result.trades

                # Sharpe ratio (annualis√©)
                if len(returns) > 0 and returns.std() > 0:
                    sharpe = (returns.mean() / returns.std()) * np.sqrt(
                        252 * 24 * 60
                    )  # 1-min bars
                else:
                    sharpe = 0.0

                # Total return
                total_return = (result.equity.iloc[-1] / result.equity.iloc[0]) - 1

                # Max drawdown
                equity = result.equity
                cummax = equity.cummax()
                drawdown = (equity - cummax) / cummax
                max_drawdown = drawdown.min()

                # Win rate
                if len(trades) > 0:
                    win_rate = (trades["pnl"] > 0).sum() / len(trades)
                else:
                    win_rate = 0.0

                # Profit factor
                if len(trades) > 0:
                    wins = trades[trades["pnl"] > 0]["pnl"].sum()
                    losses = abs(trades[trades["pnl"] < 0]["pnl"].sum())
                    profit_factor = wins / losses if losses > 0 else float("inf")
                else:
                    profit_factor = 1.0

                return {
                    "sharpe_ratio": float(sharpe),
                    "total_return": float(total_return),
                    "max_drawdown": float(max_drawdown),
                    "win_rate": float(win_rate),
                    "profit_factor": float(profit_factor),
                }

            except Exception as e:
                self.logger.error(f"‚ùå Erreur dans backtest_func split: {e}")
                # Retourner m√©triques nulles en cas d'erreur
                return {
                    "sharpe_ratio": 0.0,
                    "total_return": 0.0,
                    "max_drawdown": 0.0,
                    "win_rate": 0.0,
                    "profit_factor": 0.0,
                }

        # Ex√©cuter validation compl√®te
        self.logger.info(
            f"üîÑ Validation {config.method} avec {config.walk_forward_windows if config.method == 'walk_forward' else 1} splits"
        )
        validation_results = validator.validate_backtest(
            backtest_func=backtest_func, data=df_1m, params=params
        )

        # Logs r√©sultats
        self.logger.info("üìä R√©sultats validation:")
        self.logger.info(
            f"   In-Sample Sharpe: {validation_results['in_sample']['mean_sharpe_ratio']:.2f} "
            f"¬± {validation_results['in_sample']['std_sharpe_ratio']:.2f}"
        )
        self.logger.info(
            f"   Out-Sample Sharpe: {validation_results['out_sample']['mean_sharpe_ratio']:.2f} "
            f"¬± {validation_results['out_sample']['std_sharpe_ratio']:.2f}"
        )
        self.logger.info(
            f"   Overfitting Ratio: {validation_results['overfitting_ratio']:.2f}"
        )

        # Alerte si overfitting critique
        if validation_results["overfitting_ratio"] > 2.0:
            self.logger.warning(
                "üî¥ ALERTE: Overfitting critique d√©tect√©! Strat√©gie non fiable."
            )
        elif validation_results["overfitting_ratio"] > 1.5:
            self.logger.warning(
                "üü° ATTENTION: Overfitting mod√©r√©, r√©duire nombre param√®tres."
            )
        else:
            self.logger.info("‚úÖ Strat√©gie robuste, overfitting acceptable.")

        self.logger.info(f"\n{validation_results['recommendation']}\n")

        return validation_results


# === Factory Functions et API Convenience ===


def create_engine(
    gpu_balance: Optional[Dict[str, float]] = None, use_multi_gpu: bool = True
) -> BacktestEngine:
    """
    Factory function pour cr√©er une instance BacktestEngine.

    Args:
        gpu_balance: Balance multi-GPU personnalis√©e
        use_multi_gpu: Active multi-GPU si disponible

    Returns:
        BacktestEngine: Instance configur√©e

    Examples:
        >>> # Moteur par d√©faut (balance auto)
        >>> engine = create_engine()
        >>>
        >>> # Balance personnalis√©e 80/20
        >>> engine = create_engine(gpu_balance={"5090": 0.8, "2060": 0.2})
        >>>
        >>> # Force single GPU
        >>> engine = create_engine(use_multi_gpu=False)
    """
    return BacktestEngine(gpu_balance=gpu_balance, use_multi_gpu=use_multi_gpu)


def run(
    df_1m: pd.DataFrame,
    indicators: Dict[str, Any],
    *,
    params: Dict[str, Any],
    symbol: str,
    timeframe: str,
    seed: int = 42,
    use_gpu: Optional[bool] = None,
    gpu_balance: Optional[Dict[str, float]] = None,
) -> RunResult:
    """
    Fonction de convenience pour ex√©cution directe sans instanciation.

    √âquivalent √† BacktestEngine().run(...) mais plus concise pour usage ponctuel.
    Cr√©e une instance temporaire, ex√©cute, et retourne RunResult.

    Args:
        df_1m: DataFrame OHLCV
        indicators: Dict indicateurs de bank.ensure
        params: Param√®tres strat√©gie
        symbol: Symbole trad√©
        timeframe: Timeframe
        seed: Seed d√©terminisme
        use_gpu: Force GPU usage
        gpu_balance: Balance multi-GPU

    Returns:
        RunResult: Pr√™t pour performance.summarize()

    Examples:
        >>> # Usage minimal
        >>> result = run(df_1m, indicators, params={"entry_z": 2.0, "k_sl": 1.5, "leverage": 3},
        ...              symbol="BTCUSDC", timeframe="1m")
        >>>
        >>> # Avec configuration GPU
        >>> result = run(df_1m, indicators, params=params, symbol="ETHUSDC", timeframe="15m",
        ...              use_gpu=True, gpu_balance={"5090": 0.9, "2060": 0.1})
    """
    engine = BacktestEngine(gpu_balance=gpu_balance, use_multi_gpu=True)
    return engine.run(
        df_1m=df_1m,
        indicators=indicators,
        params=params,
        symbol=symbol,
        timeframe=timeframe,
        seed=seed,
        use_gpu=use_gpu,
    )


# === Module Initialization ===
logger.info(f"ThreadX Backtest Engine v10 loaded")
logger.debug(f"   GPU utils: {'‚úÖ' if GPU_UTILS_AVAILABLE else '‚ùå'}")
logger.debug(f"   XP utils: {'‚úÖ' if XP_AVAILABLE else '‚ùå'}")
logger.debug(f"   Timing utils: {'‚úÖ' if 'measure_throughput' in globals() else '‚ùå'}")
