"""
Test des optimisations GPU Phase 2
==================================

Test rapide des amÃ©liorations:
1. Auto-balance profiling avec warmup + efficacitÃ© mÃ©moire
2. Kernels Numba CUDA fusionnÃ©s (Bollinger Bands)
3. Configuration thread/block optimale
"""

import sys
import numpy as np
import pandas as pd
from pathlib import Path

# Ajout du path src pour imports
sys.path.insert(0, str(Path(__file__).parent / "src"))


def test_multi_gpu_profiling():
    """Test auto-balance profiling amÃ©liorÃ©."""
    print("\n" + "=" * 60)
    print("TEST 1: Auto-Balance Profiling HÃ©tÃ©rogÃ¨ne")
    print("=" * 60)

    try:
        from threadx.utils.gpu import get_default_manager

        manager = get_default_manager()

        print(f"\nğŸ“Š Devices disponibles: {len(manager.available_devices)}")
        for device in manager.available_devices:
            print(
                f"  - {device.name}: {device.memory_total_gb:.2f} GB, "
                f"compute {device.compute_capability}"
            )

        print(f"\nâš–ï¸  Balance actuelle: {manager.device_balance}")

        # Test profiling avec warmup + efficacitÃ© mÃ©moire
        print("\nğŸ”¬ Lancement auto-profiling (sample_size=50000, warmup=2, runs=3)...")
        optimal_ratios = manager.profile_auto_balance(
            sample_size=50000, warmup=2, runs=3
        )

        print(f"\nâœ… Ratios optimaux calculÃ©s: {optimal_ratios}")

        # Stats devices
        print("\nğŸ“ˆ Stats devices aprÃ¨s profiling:")
        stats = manager.get_device_stats()
        for device_name, device_stats in stats.items():
            print(f"  {device_name}:")
            print(f"    - Balance: {device_stats['current_balance']:.1%}")
            print(f"    - MÃ©moire: {device_stats['memory_used_pct']:.1f}%")
            print(f"    - Has stream: {device_stats['has_stream']}")

        print("\nâœ… TEST 1 PASSED: Auto-balance profiling OK")
        return True

    except Exception as e:
        print(f"\nâŒ TEST 1 FAILED: {e}")
        import traceback

        traceback.print_exc()
        return False


def test_numba_bollinger():
    """Test kernels Numba CUDA fusionnÃ©s."""
    print("\n" + "=" * 60)
    print("TEST 2: Kernels Numba CUDA FusionnÃ©s (Bollinger)")
    print("=" * 60)

    try:
        from threadx.indicators.gpu_integration import get_gpu_accelerated_bank

        # DonnÃ©es test
        n = 10000
        prices = np.random.randn(n).cumsum() + 100
        df = pd.DataFrame(
            {
                "close": prices,
                "high": prices + np.random.rand(n) * 2,
                "low": prices - np.random.rand(n) * 2,
                "volume": np.random.randint(1000, 10000, n),
            }
        )

        print(f"\nğŸ“Š DonnÃ©es test: {len(df)} lignes")

        bank = get_gpu_accelerated_bank()

        # Test avec GPU forcÃ© (tentera Numba si disponible)
        print("\nâš¡ Calcul Bollinger Bands (GPU forcÃ©)...")
        upper, middle, lower = bank.bollinger_bands(
            df, period=20, std_dev=2.0, use_gpu=True
        )

        print(f"  - Upper band: {upper.iloc[-5:].values}")
        print(f"  - Middle band: {middle.iloc[-5:].values}")
        print(f"  - Lower band: {lower.iloc[-5:].values}")

        # VÃ©rification basique
        assert len(upper) == len(df), "Taille output incorrecte"
        assert not upper.isna().all(), "Output vide"

        print("\nâœ… TEST 2 PASSED: Kernels Numba/GPU OK")
        return True

    except Exception as e:
        print(f"\nâŒ TEST 2 FAILED: {e}")
        import traceback

        traceback.print_exc()
        return False


def test_performance_comparison():
    """Test comparaison CPU vs GPU vs Numba."""
    print("\n" + "=" * 60)
    print("TEST 3: Comparaison Performance CPU vs GPU")
    print("=" * 60)

    try:
        from threadx.indicators.gpu_integration import get_gpu_accelerated_bank
        import time

        # DonnÃ©es test plus grandes
        n = 100000
        prices = np.random.randn(n).cumsum() + 100
        df = pd.DataFrame(
            {
                "close": prices,
                "high": prices + np.random.rand(n) * 2,
                "low": prices - np.random.rand(n) * 2,
                "volume": np.random.randint(1000, 10000, n),
            }
        )

        print(f"\nğŸ“Š Benchmark sur {len(df):,} lignes")

        bank = get_gpu_accelerated_bank()

        # CPU
        print("\nğŸŒ Test CPU...")
        t0 = time.time()
        _, _, _ = bank.bollinger_bands(df, period=20, use_gpu=False)
        cpu_time = time.time() - t0
        print(f"  Temps CPU: {cpu_time:.4f}s")

        # GPU (auto-dÃ©cision, tentera Numba si disponible)
        print("\nâš¡ Test GPU (auto-dÃ©cision)...")
        t0 = time.time()
        _, _, _ = bank.bollinger_bands(df, period=20, use_gpu=None)
        gpu_time = time.time() - t0
        print(f"  Temps GPU: {gpu_time:.4f}s")

        speedup = cpu_time / gpu_time
        print(f"\nğŸš€ Speedup: {speedup:.2f}x")

        if speedup > 1.0:
            print("âœ… GPU plus rapide que CPU")
        else:
            print("âš ï¸  CPU plus rapide (normal pour petites donnÃ©es ou sans Numba)")

        print("\nâœ… TEST 3 PASSED: Benchmark terminÃ©")
        return True

    except Exception as e:
        print(f"\nâŒ TEST 3 FAILED: {e}")
        import traceback

        traceback.print_exc()
        return False


def main():
    """Lance tous les tests."""
    print("\n" + "=" * 70)
    print(" ğŸš€ TESTS OPTIMISATIONS GPU PHASE 2 - ThreadX v2.0")
    print("=" * 70)

    print("\nOptimisations testÃ©es:")
    print("  âœ… Auto-balance profiling hÃ©tÃ©rogÃ¨ne (warmup + mem_efficiency)")
    print("  âœ… Kernels Numba CUDA fusionnÃ©s (SMA+std)")
    print("  âœ… Configuration thread/block optimale (256 threads/block)")
    print("  âœ… Cascade fallback: Numba â†’ CuPy â†’ CPU")

    results = []

    # Test 1: Multi-GPU profiling
    results.append(("Auto-Balance Profiling", test_multi_gpu_profiling()))

    # Test 2: Numba kernels
    results.append(("Kernels Numba CUDA", test_numba_bollinger()))

    # Test 3: Performance
    results.append(("Benchmark CPU vs GPU", test_performance_comparison()))

    # RÃ©sumÃ©
    print("\n" + "=" * 70)
    print(" ğŸ“Š RÃ‰SUMÃ‰ DES TESTS")
    print("=" * 70)

    for name, passed in results:
        status = "âœ… PASSED" if passed else "âŒ FAILED"
        print(f"  {status} - {name}")

    total_passed = sum(1 for _, p in results if p)
    total_tests = len(results)

    print(f"\nğŸ¯ Score: {total_passed}/{total_tests} tests rÃ©ussis")

    if total_passed == total_tests:
        print("\nğŸ‰ TOUS LES TESTS PASSED - Optimisations opÃ©rationnelles!")
        return 0
    else:
        print("\nâš ï¸  CERTAINS TESTS FAILED - VÃ©rifier logs ci-dessus")
        return 1


if __name__ == "__main__":
    sys.exit(main())
